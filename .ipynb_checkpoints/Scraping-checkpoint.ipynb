{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e668c535",
   "metadata": {},
   "source": [
    "# The goal of this project is to analyse the monthly trends of different articles views on wikipedia based on mobile (divided into application and web) and desktop access. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2353955",
   "metadata": {},
   "source": [
    "Here we import all relevant libraries needed for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28157f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# These are standard python modules\n",
    "import json, time, urllib.parse\n",
    "#\n",
    "# The 'requests' module is not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd37ede",
   "metadata": {},
   "source": [
    "I Import the dataset of articles provided to us and extract the names of the articles which would be used later on\n",
    "to pass to our API for extraction of views on a monthly basis. The extract names are reshaped to match the formatting requirement for our API. The dataset is available on https://docs.google.com/spreadsheets/d/1A1h_7KAo7KXaVxdScJmIVPTvjb3IuY9oZhNV4ZHxrxw/edit#gid=1229854301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c95bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('thank_the_academy.AUG.2023.csv')\n",
    "names = df['name'].values\n",
    "names.reshape(-1)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdf4b7",
   "metadata": {},
   "source": [
    "The following method to call API is developed by Dr. David W. McDonald(following four cells are from here). This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - August 14, 2023\n",
    "\n",
    "The API documentation, [pageviews/per-article](https://wikimedia.org/api/rest_v1/#/Pageviews%20data), covers additional details that may be helpful when trying to use or understand this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addda5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "API_REQUEST_PAGEVIEWS_ENDPOINT = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "API_REQUEST_PER_ARTICLE_PARAMS = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include your email address which will allow them\n",
    "# to contact you if something happens - such as - your code exceeding rate limits - or some other error \n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<uwnetid@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "#ARTICLE_TITLES = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "ARTICLE_TITLES = names \n",
    "# This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. The dictionary has a\n",
    "# field/key for each of the required parameters. In the example, below, we only vary the article name, so the majority of the fields\n",
    "# can stay constant for each request. Of course, these values *could* be changed if necessary.\n",
    "ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015010100\",   # start and end dates need to be set\n",
    "    \"end\":         \"2023010100\"    # this is likely the wrong end date\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e0e94",
   "metadata": {},
   "source": [
    "The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title.\n",
    "\n",
    "Note that this is slightly modified to automate introducing device_type as the function parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996a17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageviews_per_article(article_title = None, device_type = None,\n",
    "                                  endpoint_url = API_REQUEST_PAGEVIEWS_ENDPOINT, \n",
    "                                  endpoint_params = API_REQUEST_PER_ARTICLE_PARAMS, \n",
    "                                  request_template = ARTICLE_PAGEVIEWS_PARAMS_TEMPLATE,\n",
    "                                  headers = REQUEST_HEADERS):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "    \n",
    "    if device_type:\n",
    "        request_template['access'] = device_type\n",
    "        \n",
    "    if not request_template['access']:\n",
    "        raise Exception(\"Must supply a device type to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af11004",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting pageview data for: \",ARTICLE_TITLES[1])\n",
    "views = request_pageviews_per_article(article_title = ARTICLE_TITLES[1], device_type = 'mobile-app')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538b181",
   "metadata": {},
   "source": [
    "Printing sample output for one article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9039b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(views,indent=4))\n",
    "#print(\"Have %d months of pageview data\"%(len(views['items'])))\n",
    "for month in views['items']:\n",
    "    print(json.dumps(month,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae621df7",
   "metadata": {},
   "source": [
    "The following code extracts views for all articles only with desktop access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52e6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_desktop = []\n",
    "for i in range(len(ARTICLE_TITLES)):\n",
    "    views = request_pageviews_per_article(article_title = ARTICLE_TITLES[i], device_type = 'desktop')\n",
    "    merged_desktop.extend(views['items'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4f119",
   "metadata": {},
   "source": [
    "Here I print the json file for all articles views with desktop access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b93eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in merged_desktop:\n",
    "    print(json.dumps(month,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd1a3f",
   "metadata": {},
   "source": [
    "In the below cell the same steps are repeated as performed above first for mobile-web and then for mobile-app. Mobile-web is basically getting views for articles month wise for users who accessed through browser using mobile. Mobile-app\n",
    "is getting views for articles month wise for users who accessed through mobile application. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mobile_web = []\n",
    "for i in range(len(ARTICLE_TITLES)):\n",
    "    views = request_pageviews_per_article(article_title = ARTICLE_TITLES[i], device_type = 'mobile-web')\n",
    "    merged_mobile_web.extend(views['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752027bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in merged_mobile_web:\n",
    "    print(json.dumps(month,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff350d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mobile_app = []\n",
    "for i in range(len(ARTICLE_TITLES)):\n",
    "    views = request_pageviews_per_article(article_title = ARTICLE_TITLES[i], device_type = 'mobile-app')\n",
    "    merged_mobile_app.extend(views['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c743946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in merged_mobile_app:\n",
    "    print(json.dumps(month,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a0ffd",
   "metadata": {},
   "source": [
    "In the below cell I have combined the views contained in the json file for different categories of mobile. The main thought process behind the following algorithm is to look for matches with same article name and same timestamp. Then sum their views to return total mobile views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2_dict = {(item['article'], item['timestamp']): item for item in merged_mobile_app}\n",
    "\n",
    "# Initialize a new list to store merged data\n",
    "merged_list = []\n",
    "\n",
    "# Loop through entries in list1\n",
    "for item1 in merged_mobile_web:\n",
    "    # Check if a matching entry exists in list2_dict\n",
    "    key = (item1['article'], item1['timestamp'])\n",
    "    if key in list2_dict:\n",
    "        # Create a merged entry with the common 'article' and 'timestamp'\n",
    "        merged_entry = {\n",
    "            \"project\": item1[\"project\"],\n",
    "            \"article\": item1[\"article\"],\n",
    "            \"granularity\": item1[\"granularity\"],\n",
    "            \"timestamp\": item1[\"timestamp\"],\n",
    "            \"access_app\": item1[\"access\"],\n",
    "            \"access_web\": list2_dict[key][\"access\"],\n",
    "            \"agent\": item1[\"agent\"],\n",
    "            \"views_app\": item1[\"views\"],\n",
    "            \"views_web\": list2_dict[key][\"views\"],\n",
    "            \"total_views\": item1[\"views\"] + list2_dict[key][\"views\"]  # Calculate the sum of views\n",
    "        }\n",
    "        merged_list.append(merged_entry)\n",
    "\n",
    "# Now, merged_list contains the combined data with the total views\n",
    "for item in merged_list:\n",
    "    print(json.dumps(item, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1dbf59",
   "metadata": {},
   "source": [
    "In the below cell I have combined the views for mobile from the output of the above cell with the views of the desktop file we had. The core algorithm is the same as above. However, this outputs the combined views from desktop and mobile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24691a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to efficiently match entries based on 'article' and 'timestamp'\n",
    "list3_dict = {(item['article'], item['timestamp']): item for item in merged_desktop}\n",
    "\n",
    "# Initialize a new list to store the final merged data\n",
    "final_merged_list = []\n",
    "\n",
    "# Loop through entries in merged_list\n",
    "for merged_entry in merged_list:\n",
    "    # Check if a matching entry exists in list3_dict\n",
    "    key = (merged_entry['article'], merged_entry['timestamp'])\n",
    "    if key in list3_dict:\n",
    "        # Update the merged entry with data from list3_dict\n",
    "        merged_entry[\"access_desktop\"] = list3_dict[key][\"access\"]\n",
    "        merged_entry[\"views_desktop\"] = list3_dict[key][\"views\"]\n",
    "        merged_entry[\"total_views\"] += list3_dict[key][\"views\"]  # Update the total views\n",
    "    else:\n",
    "        # If no match is found, add the merged entry as is\n",
    "        merged_entry[\"access_desktop\"] = None\n",
    "        merged_entry[\"views_desktop\"] = None\n",
    "\n",
    "    final_merged_list.append(merged_entry)\n",
    "\n",
    "# Now, final_merged_list contains the combined data with mobile-app, mobile-web, and desktop data\n",
    "for item in final_merged_list:\n",
    "    print(json.dumps(item, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bf5a0",
   "metadata": {},
   "source": [
    "The views from desktop are saved into a json file showing the start and end year and month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the JSON data\n",
    "file_path = \"academy_monthly_desktop_<start201501>-<end202309>.json\"\n",
    "\n",
    "# Open the file in write mode and use json.dump() to write the list to the file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(merged_desktop, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744244c4",
   "metadata": {},
   "source": [
    "The views from mobile are saved into a json file showing the start and end year and month. Note that this is the combined output(mobile-app + mobile-web). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the JSON data\n",
    "file_path = \"academy_monthly_mobile_<start201501>-<end202309>.json\"\n",
    "\n",
    "# Open the file in write mode and use json.dump() to write the list to the file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(merged_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d810e3f",
   "metadata": {},
   "source": [
    "The combined views from desktop and mobile are saved into a json file showing the start and end year and month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the JSON data\n",
    "file_path = \"academy_monthly_cummulative_<start201501>-<end202309>.json\"\n",
    "\n",
    "# Open the file in write mode and use json.dump() to write the list to the file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(final_merged_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d8dc7",
   "metadata": {},
   "source": [
    "The json file with combined views into converted into a dataframe for further EDA and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362988e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_merged_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14f697",
   "metadata": {},
   "source": [
    "I have extracted only mobile views and created a new column named views_mobile as it will be needed in future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b98425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['views_mobile'] = df['views_app'] + df['views_web']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea79bfe",
   "metadata": {},
   "source": [
    "Over here I have grouped by article to find monthly average total views for each article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_desktop = df.groupby('article')['total_views'].mean()\n",
    "result_mobile = df.groupby('article')['total_views'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721275b",
   "metadata": {},
   "source": [
    "To analyze the article with the highest and lowest views I have first of all sorted the articles by their monthly average views and then selected the first and the last name as they are the ones with the lowest and highest views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c84181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_desktop = result_desktop.sort_values()\n",
    "names_desktop = df_sorted_desktop.index.tolist()\n",
    "max_views_desktop_name = names_desktop[-1]\n",
    "min_views_desktop_name = names_desktop[0]\n",
    "\n",
    "df_sorted_mobile = result_mobile.sort_values()\n",
    "names_mobile = df_sorted_mobile.index.tolist()\n",
    "max_views_mobile_name = names_mobile[-1]\n",
    "min_views_mobile_name = names_mobile[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84daadc1",
   "metadata": {},
   "source": [
    "To visualize the trends I have created smaller dataframes with only views and timestamps where the article name is the same as required by us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_array_desktop = df[['views_desktop', 'timestamp']][df['article'] == max_views_desktop_name]\n",
    "min_array_desktop = df[['views_desktop', 'timestamp']][df['article'] == min_views_desktop_name]\n",
    "\n",
    "\n",
    "max_array_mobile = df[['views_mobile', 'timestamp']][df['article'] == max_views_mobile_name]\n",
    "min_array_mobile = df[['views_mobile', 'timestamp']][df['article'] == min_views_mobile_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398993ef",
   "metadata": {},
   "source": [
    "Plotted a line graph and labelled it for proper understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b57922",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  \n",
    "plt.plot(max_array_desktop['timestamp'], max_array_desktop['views_desktop'], \n",
    "         label = f'max_views_desktop ({max_views_desktop_name})')\n",
    "plt.plot(min_array_desktop['timestamp'], min_array_desktop['views_desktop'], \n",
    "         label = f'min_views_desktop ({min_views_desktop_name})')\n",
    "plt.plot(max_array_mobile['timestamp'], max_array_mobile['views_mobile'], \n",
    "         label = f'max_views_mobile ({max_views_mobile_name})')\n",
    "plt.plot(min_array_mobile['timestamp'], min_array_mobile['views_mobile'], \n",
    "         label = f'min_views_mobile ({min_views_mobile_name})')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('total_views')\n",
    "plt.title('Line Plot with Rotated Y-axis Labels')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe67caf",
   "metadata": {},
   "source": [
    "Created a dataframe from json file of only mobile views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mobile = pd.DataFrame(merged_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b76d6a",
   "metadata": {},
   "source": [
    "In the following cells I have extracted the number of times each article is appearing in our dataset. Basically this tells us the number of months for which we have data for each article. I have picked up the lowest 10 articles in this case and did my analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_month_counts = df_mobile['article'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_month_counts[90:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145cff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_mobile_month_counts = mobile_month_counts.sort_values()\n",
    "mobile_article_names = mobile_month_counts.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c41c28",
   "metadata": {},
   "source": [
    "Same steps are repeated for desktop views only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf51dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desktop = pd.DataFrame(merged_desktop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87880c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_month_counts = df_desktop['article'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_month_counts[90:101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89235e7",
   "metadata": {},
   "source": [
    "Since the last ten "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883494c",
   "metadata": {},
   "source": [
    "Movies with lowest months of data available are extracted and their graphs are plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf40d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_month_counts = desktop_month_counts.index.tolist()[91:101]\n",
    "mobile_month_counts = mobile_month_counts.index.tolist()[91:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dedf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))  \n",
    "j = 1\n",
    "labels = []\n",
    "plt.xticks(rotation=90)\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "# Customize the tick spacing on the X-axis using MultipleLocator\n",
    "x_locator = ticker.MultipleLocator(base=2)  # Adjust the base value as needed\n",
    "# Apply the locator to the X-axis\n",
    "plt.gca().xaxis.set_major_locator(x_locator)\n",
    "for i in range(10):\n",
    "    temp = df[['views_desktop', 'timestamp']][df['article'] == desktop_month_counts[i]]\n",
    "    temp2 = df[['views_mobile', 'timestamp']][df['article'] == mobile_month_counts[i]]\n",
    "    sorted_temp = temp.sort_values(by='timestamp')\n",
    "    sorted_temp2 = temp2.sort_values(by='timestamp')\n",
    "    plt.plot(sorted_temp['timestamp'], sorted_temp['views_desktop'],\n",
    "                label=f'{desktop_month_counts[i]} (desktop)')\n",
    "    labels.append(f'{desktop_month_counts[i]} (desktop)')\n",
    "    plt.plot(sorted_temp2['timestamp'], sorted_temp2['views_mobile'], \n",
    "                label=f'{mobile_month_counts[i]} (mobile)')\n",
    "    labels.append(f'{mobile_month_counts[i]} (mobile)')\n",
    "\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d129bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
